(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[974],{230:(e,t,a)=>{Promise.resolve().then(a.bind(a,8171))},5016:(e,t,a)=>{"use strict";function i(e){let t="/implementation-catalog",a=e.startsWith("/")?e.slice(1):e;return t?"".concat(t,"/").concat(a):"/".concat(a)}a.d(t,{O:()=>i})},8171:(e,t,a)=>{"use strict";a.r(t),a.d(t,{default:()=>N});var i=a(5155),r=a(2115),n=a(5239),s=a(273),l=a(1847);let o=(0,l.A)("layers",[["path",{d:"M12.83 2.18a2 2 0 0 0-1.66 0L2.6 6.08a1 1 0 0 0 0 1.83l8.58 3.91a2 2 0 0 0 1.66 0l8.58-3.9a1 1 0 0 0 0-1.83z",key:"zw3jo"}],["path",{d:"M2 12a1 1 0 0 0 .58.91l8.6 3.91a2 2 0 0 0 1.65 0l8.58-3.9A1 1 0 0 0 22 12",key:"1wduqc"}],["path",{d:"M2 17a1 1 0 0 0 .58.91l8.6 3.91a2 2 0 0 0 1.65 0l8.58-3.9A1 1 0 0 0 22 17",key:"kqbvx6"}]]);var c=a(1524),m=a(8803),u=a(5016);function d(e){let{totalImplementations:t,yearsOfResearch:a}=e;return(0,i.jsxs)("div",{className:"relative min-h-screen flex items-center justify-center overflow-hidden bg-gradient-to-br from-white via-gray-50 to-gray-100",children:[(0,i.jsx)(s.P.div,{className:"absolute -top-48 -left-48 w-[900px] h-[900px]",style:{background:"radial-gradient(circle at 50% 50%, rgba(235, 8, 138, 0.12) 0%, rgba(235, 8, 138, 0.08) 35%, rgba(235, 8, 138, 0.04) 60%, transparent 80%)",filter:"blur(60px)",borderRadius:"63% 37% 54% 46% / 55% 48% 52% 45%"},animate:{borderRadius:["63% 37% 54% 46% / 55% 48% 52% 45%","40% 60% 48% 52% / 45% 55% 45% 55%","58% 42% 55% 45% / 48% 52% 45% 55%","63% 37% 54% 46% / 55% 48% 52% 45%"],x:[0,40,-20,0],y:[0,30,-15,0],scale:[1,1.08,.98,1]},transition:{duration:18,repeat:1/0,ease:[.45,.05,.55,.95]}}),(0,i.jsx)(s.P.div,{className:"absolute -bottom-32 -right-32 w-[800px] h-[800px]",style:{background:"radial-gradient(circle at 50% 50%, rgba(49, 60, 255, 0.10) 0%, rgba(49, 60, 255, 0.06) 35%, rgba(49, 60, 255, 0.03) 60%, transparent 80%)",filter:"blur(65px)",borderRadius:"45% 55% 52% 48% / 48% 55% 45% 52%"},animate:{borderRadius:["45% 55% 52% 48% / 48% 55% 45% 52%","55% 45% 48% 52% / 52% 48% 52% 48%","48% 52% 58% 42% / 55% 45% 48% 52%","45% 55% 52% 48% / 48% 55% 45% 52%"],x:[0,-35,20,0],y:[0,25,-30,0],scale:[1,.96,1.06,1]},transition:{duration:22,repeat:1/0,ease:[.45,.05,.55,.95],delay:.5}}),(0,i.jsx)(s.P.div,{className:"absolute top-1/2 left-1/2 -translate-x-1/2 -translate-y-1/2 w-[750px] h-[750px]",style:{background:"radial-gradient(circle at 50% 50%, rgba(235, 8, 138, 0.08) 0%, rgba(49, 60, 255, 0.06) 40%, rgba(235, 8, 138, 0.03) 60%, transparent 80%)",filter:"blur(70px)",borderRadius:"52% 48% 45% 55% / 55% 45% 55% 45%"},animate:{borderRadius:["52% 48% 45% 55% / 55% 45% 55% 45%","48% 52% 55% 45% / 45% 55% 48% 52%","55% 45% 50% 50% / 52% 48% 45% 55%","52% 48% 45% 55% / 55% 45% 55% 45%"],rotate:[0,90,180,270,360],scale:[1,1.05,.98,1.02,1]},transition:{duration:25,repeat:1/0,ease:[.42,0,.58,1]}}),(0,i.jsx)(s.P.div,{className:"absolute top-1/4 right-1/4 w-[500px] h-[500px]",style:{background:"radial-gradient(circle at 50% 50%, rgba(49, 60, 255, 0.08) 0%, rgba(49, 60, 255, 0.04) 50%, transparent 75%)",filter:"blur(50px)",borderRadius:"58% 42% 48% 52% / 52% 55% 45% 48%"},animate:{borderRadius:["58% 42% 48% 52% / 52% 55% 45% 48%","45% 55% 55% 45% / 48% 52% 55% 45%","58% 42% 48% 52% / 52% 55% 45% 48%"],x:[0,25,0],y:[0,-20,0],scale:[1,1.04,1]},transition:{duration:16,repeat:1/0,ease:[.65,0,.35,1],delay:1}}),(0,i.jsxs)("div",{className:"relative z-10 max-w-5xl mx-auto px-6 text-center",children:[(0,i.jsx)(s.P.div,{initial:{opacity:0,y:-20},animate:{opacity:1,y:0},transition:{duration:.6},className:"mb-8 flex justify-center",children:(0,i.jsx)(n.default,{src:(0,u.O)("vector-logo.svg"),alt:"Vector Institute",width:140,height:46,className:"object-contain"})}),(0,i.jsxs)(s.P.h1,{initial:{opacity:0,y:20},animate:{opacity:1,y:0},transition:{duration:.6,delay:.2},className:"text-5xl md:text-7xl font-bold mb-6 text-gray-900 leading-tight",children:["Implementation ",(0,i.jsx)("span",{className:"bg-gradient-to-r from-vector-magenta to-vector-cobalt bg-clip-text text-transparent",children:"Catalog"})]}),(0,i.jsx)(s.P.p,{initial:{opacity:0,y:20},animate:{opacity:1,y:0},transition:{duration:.6,delay:.4},className:"text-lg md:text-xl mb-12 text-gray-800 max-w-3xl mx-auto leading-relaxed font-medium",children:"Explore cutting-edge AI implementations from Vector Institute researchers and engineers"}),(0,i.jsxs)(s.P.div,{initial:{opacity:0,y:20},animate:{opacity:1,y:0},transition:{duration:.6,delay:.6},className:"flex flex-wrap justify-center gap-8 md:gap-16 mb-12",children:[(0,i.jsxs)("div",{className:"flex items-center gap-3",children:[(0,i.jsx)("div",{className:"p-3 bg-vector-magenta/10 rounded-xl border border-vector-magenta/30",children:(0,i.jsx)(o,{className:"w-6 h-6 text-vector-magenta"})}),(0,i.jsxs)("div",{className:"text-left",children:[(0,i.jsx)("div",{className:"text-3xl md:text-4xl font-bold text-gray-900",children:t}),(0,i.jsx)("div",{className:"text-sm text-gray-700 uppercase tracking-wide font-semibold",children:"Implementations"})]})]}),(0,i.jsxs)("div",{className:"flex items-center gap-3",children:[(0,i.jsx)("div",{className:"p-3 bg-vector-cobalt/10 rounded-xl border border-vector-cobalt/30",children:(0,i.jsx)(c.A,{className:"w-6 h-6 text-vector-cobalt"})}),(0,i.jsxs)("div",{className:"text-left",children:[(0,i.jsx)("div",{className:"text-3xl md:text-4xl font-bold text-gray-900",children:a}),(0,i.jsx)("div",{className:"text-sm text-gray-700 uppercase tracking-wide font-semibold",children:"Years of Research"})]})]})]}),(0,i.jsxs)(s.P.a,{href:"#browse",initial:{opacity:0,scale:.9},animate:{opacity:1,scale:1},transition:{duration:.6,delay:.8},whileHover:{scale:1.05},whileTap:{scale:.95},className:"inline-flex items-center gap-2 bg-gradient-to-r from-vector-magenta to-vector-cobalt hover:from-vector-magenta/90 hover:to-vector-cobalt/90 text-white px-10 py-4 rounded-full font-semibold text-lg shadow-lg shadow-vector-magenta/25 transition-all mb-8",children:["Browse Implementations",(0,i.jsx)(m.A,{className:"w-5 h-5 animate-bounce"})]}),(0,i.jsx)(s.P.div,{initial:{opacity:0,y:10},animate:{opacity:1,y:0},transition:{duration:.6,delay:1},className:"max-w-2xl mx-auto",children:(0,i.jsx)("div",{id:"hero-search"})})]}),(0,i.jsx)(s.P.div,{initial:{opacity:0},animate:{opacity:1},transition:{delay:1.2},className:"absolute bottom-8 left-1/2 -translate-x-1/2",children:(0,i.jsx)(s.P.div,{animate:{y:[0,10,0]},transition:{duration:2,repeat:1/0},className:"text-gray-400",children:(0,i.jsx)(m.A,{className:"w-6 h-6"})})})]})}let p=(0,l.A)("grid-3x3",[["rect",{width:"18",height:"18",x:"3",y:"3",rx:"2",key:"afitv7"}],["path",{d:"M3 9h18",key:"1pudct"}],["path",{d:"M3 15h18",key:"5xshup"}],["path",{d:"M9 3v18",key:"fh3hqa"}],["path",{d:"M15 3v18",key:"14nvp0"}]]),h=(0,l.A)("flask-conical",[["path",{d:"M14 2v6a2 2 0 0 0 .245.96l5.51 10.08A2 2 0 0 1 18 22H6a2 2 0 0 1-1.755-2.96l5.51-10.08A2 2 0 0 0 10 8V2",key:"18mbvz"}],["path",{d:"M6.453 15h11.094",key:"3shlmq"}],["path",{d:"M8.5 2h7",key:"csnxdl"}]]),g=[{key:"all",label:"All",icon:p},{key:"applied-research",label:"Applied Research",icon:h},{key:"bootcamp",label:"Bootcamp",icon:(0,l.A)("sparkles",[["path",{d:"M11.017 2.814a1 1 0 0 1 1.966 0l1.051 5.558a2 2 0 0 0 1.594 1.594l5.558 1.051a1 1 0 0 1 0 1.966l-5.558 1.051a2 2 0 0 0-1.594 1.594l-1.051 5.558a1 1 0 0 1-1.966 0l-1.051-5.558a2 2 0 0 0-1.594-1.594l-5.558-1.051a1 1 0 0 1 0-1.966l5.558-1.051a2 2 0 0 0 1.594-1.594z",key:"1s2grr"}],["path",{d:"M20 2v4",key:"1rf3ol"}],["path",{d:"M22 4h-4",key:"gwowj6"}],["circle",{cx:"4",cy:"20",r:"2",key:"6kqj1y"}]])},{key:"tool",label:"Tool",icon:(0,l.A)("wrench",[["path",{d:"M14.7 6.3a1 1 0 0 0 0 1.4l1.6 1.6a1 1 0 0 0 1.4 0l3.106-3.105c.32-.322.863-.22.983.218a6 6 0 0 1-8.259 7.057l-7.91 7.91a1 1 0 0 1-2.999-3l7.91-7.91a6 6 0 0 1 7.057-8.259c.438.12.54.662.219.984z",key:"1ngwbx"}]])}];function b(e){let{activeFilter:t,onFilterChange:a,counts:r}=e;return(0,i.jsx)("div",{className:"flex flex-wrap justify-center gap-3 mb-12",children:g.map(e=>{let{key:n,label:l,icon:o}=e,c=r[n]||0,m=t===n;return(0,i.jsxs)(s.P.button,{onClick:()=>a(n),whileHover:{scale:1.05},whileTap:{scale:.95},className:"relative px-6 py-3 rounded-xl font-semibold transition-all ".concat(m?"bg-gradient-to-r from-vector-teal to-cyan-400 text-white shadow-lg shadow-vector-teal/25":"bg-white dark:bg-gray-800 text-gray-700 dark:text-gray-300 border-2 border-gray-200 dark:border-gray-700 hover:border-vector-teal dark:hover:border-vector-teal"),children:[m&&(0,i.jsx)(s.P.div,{layoutId:"activeTab",className:"absolute inset-0 bg-gradient-to-r from-vector-teal to-cyan-400 rounded-xl",style:{zIndex:-1},transition:{type:"spring",bounce:.2,duration:.6}}),(0,i.jsxs)("span",{className:"flex items-center gap-2",children:[(0,i.jsx)(o,{className:"w-4 h-4"}),l,(0,i.jsx)("span",{className:"text-xs px-2 py-0.5 rounded-full ".concat(m?"bg-white/20":"bg-gray-100 dark:bg-gray-700"),children:c})]})]},n)})})}var x=a(5880);let y=(0,l.A)("code-xml",[["path",{d:"m18 16 4-4-4-4",key:"1inbqp"}],["path",{d:"m6 8-4 4 4 4",key:"15zrgr"}],["path",{d:"m14.5 4-5 16",key:"e7oirm"}]]),f=(0,l.A)("database",[["ellipse",{cx:"12",cy:"5",rx:"9",ry:"3",key:"msslwz"}],["path",{d:"M3 5V19A9 3 0 0 0 21 19V5",key:"1wlel7"}],["path",{d:"M3 12A9 3 0 0 0 21 12",key:"mv7ke4"}]]),v=(0,l.A)("file-text",[["path",{d:"M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z",key:"1rqfz7"}],["path",{d:"M14 2v4a2 2 0 0 0 2 2h4",key:"tnqrlb"}],["path",{d:"M10 9H8",key:"b1mrlr"}],["path",{d:"M16 13H8",key:"t4e002"}],["path",{d:"M16 17H8",key:"z1uh3a"}]]),k=(0,l.A)("check",[["path",{d:"M20 6 9 17l-5-5",key:"1gmf2c"}]]),w=(0,l.A)("book-open",[["path",{d:"M12 7v14",key:"1akyts"}],["path",{d:"M3 18a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4 4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3 3 3 0 0 0-3-3z",key:"ruj8y"}]]);function I(e){let{repository:t,index:a=0}=e,n=t.github_url||"https://github.com/".concat(t.repo_id),l=t.name.toLowerCase().replace(/[^a-z0-9]+/g,"-"),[o,c]=(0,r.useState)(!1),m=async()=>{if(t.bibtex)try{let e=window.location.pathname.includes("/implementation-catalog")?"/implementation-catalog":"",a=await fetch("".concat(e,"/data/papers.bib")),i=await a.text(),r=RegExp("@\\w+\\{".concat(t.bibtex,",[\\s\\S]*?\\n\\}"),"i"),n=i.match(r);n&&(await navigator.clipboard.writeText(n[0]),c(!0),setTimeout(()=>c(!1),2e3))}catch(e){console.error("Failed to copy citation:",e)}};return(0,i.jsxs)(s.P.article,{id:l,initial:{opacity:0,y:20},animate:{opacity:1,y:0},transition:{duration:.4,delay:.05*a},whileHover:{y:-4},className:"group relative bg-white dark:bg-gray-800/50 backdrop-blur-sm rounded-2xl shadow-sm hover:shadow-2xl transition-all duration-300 border border-gray-200 dark:border-gray-700 p-6 overflow-hidden scroll-mt-20",children:[(0,i.jsx)("div",{className:"absolute top-0 left-0 right-0 h-1 bg-gradient-to-r from-vector-teal via-cyan-400 to-purple-500 opacity-0 group-hover:opacity-100 transition-opacity"}),(0,i.jsx)("div",{className:"absolute -top-24 -right-24 w-48 h-48 bg-vector-teal/5 rounded-full blur-3xl group-hover:bg-vector-teal/10 transition-colors duration-500"}),(0,i.jsxs)("div",{className:"relative flex items-start justify-between gap-4 mb-4",children:[(0,i.jsx)("div",{className:"flex-1",children:(0,i.jsxs)("a",{href:n,target:"_blank",rel:"noopener noreferrer",className:"group/link inline-flex items-center gap-2 text-xl font-bold text-gray-900 dark:text-white hover:text-vector-teal transition-colors",children:[t.name,(0,i.jsx)(x.A,{className:"w-4 h-4 opacity-0 group-hover/link:opacity-100 transition-opacity"})]})}),(0,i.jsxs)("div",{className:"flex flex-col sm:flex-row gap-2 flex-shrink-0",children:[(0,i.jsx)("span",{className:"inline-flex items-center gap-1 bg-vector-teal/10 text-vector-teal border border-vector-teal/30 text-xs font-semibold px-3 py-1.5 rounded-full",children:t.year}),(0,i.jsx)("span",{className:"inline-flex items-center gap-1 text-xs font-semibold px-3 py-1.5 rounded-full border ".concat({tool:"bg-emerald-500/10 text-emerald-600 dark:text-emerald-400 border-emerald-500/30",bootcamp:"bg-blue-500/10 text-blue-600 dark:text-blue-400 border-blue-500/30","applied-research":"bg-purple-500/10 text-purple-600 dark:text-purple-400 border-purple-500/30"}[t.type]),children:t.type})]})]}),(0,i.jsx)("p",{className:"text-gray-600 dark:text-gray-300 mb-5 leading-relaxed",children:t.description}),t.implementations&&t.implementations.length>0&&(0,i.jsxs)("div",{className:"mb-5",children:[(0,i.jsxs)("div",{className:"flex items-center gap-2 mb-2",children:[(0,i.jsx)(y,{className:"w-4 h-4 text-gray-500"}),(0,i.jsx)("span",{className:"text-sm font-semibold text-gray-700 dark:text-gray-300",children:"Implementations"})]}),(0,i.jsx)("div",{className:"flex flex-wrap gap-2",children:t.implementations.map((e,t)=>(0,i.jsx)("span",{children:e.url?(0,i.jsxs)("a",{href:e.url,target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center gap-1 bg-cyan-100 dark:bg-cyan-900/30 hover:bg-cyan-200 dark:hover:bg-cyan-900/50 text-cyan-700 dark:text-cyan-300 text-xs font-medium px-3 py-1.5 rounded-lg transition-all hover:scale-105",children:[e.name,(0,i.jsx)(x.A,{className:"w-3 h-3"})]}):(0,i.jsx)("span",{className:"inline-block bg-cyan-100 dark:bg-cyan-900/30 text-cyan-700 dark:text-cyan-300 text-xs font-medium px-3 py-1.5 rounded-lg",children:e.name})},t))})]}),t.public_datasets&&t.public_datasets.length>0&&(0,i.jsxs)("div",{className:"mb-5",children:[(0,i.jsxs)("div",{className:"flex items-center gap-2 mb-2",children:[(0,i.jsx)(f,{className:"w-4 h-4 text-gray-500"}),(0,i.jsx)("span",{className:"text-sm font-semibold text-gray-700 dark:text-gray-300",children:"Datasets"})]}),(0,i.jsx)("div",{className:"flex flex-wrap gap-2",children:t.public_datasets.map((e,t)=>(0,i.jsx)("span",{children:e.url?(0,i.jsxs)("a",{href:e.url,target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center gap-1 bg-purple-100 dark:bg-purple-900/30 hover:bg-purple-200 dark:hover:bg-purple-900/50 text-purple-700 dark:text-purple-300 text-xs font-medium px-3 py-1.5 rounded-lg transition-all hover:scale-105",children:[e.name,(0,i.jsx)(x.A,{className:"w-3 h-3"})]}):(0,i.jsx)("span",{className:"inline-block bg-purple-100 dark:bg-purple-900/30 text-purple-700 dark:text-purple-300 text-xs font-medium px-3 py-1.5 rounded-lg",children:e.name})},t))})]}),(t.paper_url||t.bibtex||t.platform_url)&&(0,i.jsxs)("div",{className:"flex flex-wrap gap-2 pt-4 border-t border-gray-200 dark:border-gray-700",children:[t.paper_url&&(0,i.jsxs)("a",{href:t.paper_url,target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center gap-2 text-sm bg-gray-100 dark:bg-gray-700 hover:bg-gray-200 dark:hover:bg-gray-600 text-gray-700 dark:text-gray-200 px-4 py-2 rounded-lg transition-all hover:scale-105",children:[(0,i.jsx)(v,{className:"w-4 h-4"}),"Paper"]}),t.bibtex&&(0,i.jsxs)("button",{onClick:m,className:"inline-flex items-center gap-2 text-sm bg-gray-100 dark:bg-gray-700 hover:bg-gray-200 dark:hover:bg-gray-600 text-gray-700 dark:text-gray-200 px-4 py-2 rounded-lg transition-all hover:scale-105",title:o?"Copied!":"Copy citation to clipboard",children:[o?(0,i.jsx)(k,{className:"w-4 h-4"}):(0,i.jsx)(w,{className:"w-4 h-4"}),o?"Copied!":"Cite"]}),t.platform_url&&(0,i.jsxs)("a",{href:t.platform_url,target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center gap-2 text-sm bg-blue-600 hover:bg-blue-700 text-white px-4 py-2 rounded-lg transition-all hover:scale-105",children:[(0,i.jsx)(y,{className:"w-4 h-4"}),"Open in Coder"]})]})]})}function _(){return(0,r.useEffect)(()=>{let e=document.getElementById("hero-search"),t=window.location.pathname.startsWith("/implementation-catalog")?"/implementation-catalog":"";if(e){let a=setInterval(()=>{if(window.PagefindUI){if(clearInterval(a),!document.querySelector('link[href*="pagefind-ui.css"]')){let e=document.createElement("link");e.rel="stylesheet",e.href="".concat(t,"/_pagefind/pagefind-ui.css"),document.head.appendChild(e)}let i={element:e,showSubResults:!0,showImages:!1,excerptLength:15,placeholder:"Search implementations..."};t?i.basePath="".concat(t,"/_pagefind/"):i.basePath="/_pagefind/",new window.PagefindUI(i)}},100);return setTimeout(()=>{clearInterval(a),!window.PagefindUI&&e&&0===e.children.length&&(e.innerHTML='\n            <div class="relative">\n              <input\n                type="text"\n                placeholder="Search implementations... (build required)"\n                disabled\n                class="w-full px-12 py-4 rounded-2xl border-2 border-gray-200 bg-gray-50 text-gray-500 cursor-not-allowed"\n              />\n            </div>\n          ')},5e3),()=>clearInterval(a)}},[]),null}let j=JSON.parse('{"repositories":[{"name":"bias-in-the-picture-benchmark","repo_id":"VectorInstitute/bias-in-the-picture-benchmark","description":"Benchmarking VLMs with Social-Cue News Images and LLM-as-Judge Assessment - evaluates how vision-language models handle real news images containing demographic and social attributes","implementations":[{"name":"Bias in the Picture Benchmark","url":"https://vectorinstitute.github.io/bias-in-the-picture-benchmark/"},{"name":"LLM-as-Judge Evaluation Framework","url":null},{"name":"VLM Inference Pipeline","url":null}],"public_datasets":[{"name":"Social-Cue News Images Dataset","url":"https://github.com/VectorInstitute/bias-in-the-picture-benchmark/tree/main/data"}],"type":"applied-research","year":2025,"github_url":"https://github.com/VectorInstitute/bias-in-the-picture-benchmark","paper_url":"https://arxiv.org/abs/2509.19659","bibtex":"narayanan2025biaspicturebenchmarkingvlms"},{"name":"crisp-nam","repo_id":"VectorInstitute/crisp-nam","description":"Competing Risks Interpretable Survival Prediction with Neural Additive Models","implementations":[{"name":"CRISP-NAM","url":"https://arxiv.org/abs/2505.21360"},{"name":"Neural Additive Models for Survival Analysis","url":null},{"name":"DeepHit Baseline","url":null}],"type":"applied-research","year":2025,"github_url":"https://github.com/VectorInstitute/crisp-nam","paper_url":"https://arxiv.org/abs/2505.21360","bibtex":"ramachandram2025crisp","public_datasets":[{"name":"Framingham Heart Study","url":"https://www.kaggle.com/datasets/aasheesh200/framingham-heart-study-dataset"},{"name":"Primary Biliary Cirrhosis (PBC)","url":"https://www.kaggle.com/datasets/homayoonkhadivi/primary-biliary-cirrhosis-pbc-disease-dataset"},{"name":"SUPPORT","url":null},{"name":"Synthetic Clinical Dataset","url":null}]},{"name":"fair-sense-ai","repo_id":"VectorInstitute/fair-sense-ai","description":"An AI-powered tool designed to analyze bias in text and visual content, with a focus on risk identification, mitigation, and promoting sustainable and trustworthy AI systems","implementations":[{"name":"Text Bias Analysis","url":null},{"name":"Image Bias Analysis","url":null},{"name":"Batch Text CSV Analysis","url":null},{"name":"Batch Image Analysis","url":null},{"name":"AI Risk Management","url":null},{"name":"Green AI Optimization","url":null},{"name":"Bias Scoring and Assessment","url":null}],"type":"tool","year":2025,"github_url":"https://github.com/VectorInstitute/fair-sense-ai","package_name":"fair-sense-ai"},{"name":"fed-rag","repo_id":"VectorInstitute/fed-rag","description":"An open-source framework for fine-tuning retrieval-augmented generation (RAG) systems across centralized and federated architectures with comprehensive support for state-of-the-art RAG fine-tuning methods.","implementations":[{"name":"Basic fine-tuning with FL","url":null},{"name":"RA-DIT","url":"https://arxiv.org/abs/2310.01352"}],"type":"tool","year":2025,"github_url":"https://github.com/VectorInstitute/fed-rag","package_name":"fed-rag","paper_url":"https://doi.org/10.5281/zenodo.15092361","bibtex":"fajardo2025fedrag"},{"name":"humanibench","repo_id":"VectorInstitute/humanibench","description":"A benchmark suite for evaluating Large Multimodal Models on seven Human-Centered AI principles: Fairness, Ethics, Understanding, Reasoning, Language Inclusivity, Empathy, and Robustness","implementations":[{"name":"Scene Understanding","url":null},{"name":"Instance Identity","url":null},{"name":"Multiple Choice VQA","url":null},{"name":"Multilingual Visual QA","url":null},{"name":"Visual Grounding","url":null},{"name":"Empathetic Captioning","url":null},{"name":"Image Resilience","url":null}],"public_datasets":[{"name":"HumaniBench Dataset","url":"https://huggingface.co/datasets/vector-institute/HumaniBench"}],"type":"applied-research","year":2025,"github_url":"https://github.com/VectorInstitute/humanibench","paper_url":"https://arxiv.org/abs/2505.11454","bibtex":"raza2025humanibench"},{"name":"interpretability","repo_id":"VectorInstitute/interpretability","description":"A repository providing reference implementations and resources for the 2025 Bootcamp on Interpretable and Explainable AI, covering both post-hoc explainability methods and interpretable models","implementations":[{"name":"LIME","url":"https://github.com/VectorInstitute/interpretability/tree/main/implementations/Post-hoc/LIME"},{"name":"SHAP","url":"https://github.com/VectorInstitute/interpretability/tree/main/implementations/Post-hoc/SHAP"},{"name":"PDP (Partial Dependence Plot)","url":"https://github.com/VectorInstitute/interpretability/tree/main/implementations/Post-hoc/partial_dependence_plots"},{"name":"ALE (Accumulated Local Effects)","url":"https://github.com/VectorInstitute/interpretability/tree/main/implementations/Post-hoc/acc_local_effects"},{"name":"Integrated Gradients","url":"https://github.com/VectorInstitute/interpretability/tree/main/implementations/Post-hoc/integrated_gradients"},{"name":"Counterfactual Explanations","url":"https://github.com/VectorInstitute/interpretability/tree/main/implementations/Post-hoc/counterfactual"},{"name":"Generalized Additive Model","url":"https://github.com/VectorInstitute/interpretability/tree/main/implementations/Intepretable-models/Tabular/GAM"},{"name":"Neural Additive Model","url":"https://github.com/VectorInstitute/interpretability/tree/main/implementations/Intepretable-models/Tabular/NAM-NodeGAM"},{"name":"Explainable Boosting Machine","url":"https://github.com/VectorInstitute/interpretability/tree/main/implementations/Intepretable-models/Tabular/EBM"}],"public_datasets":[{"name":"Gas turbine dataset","url":"https://archive.ics.uci.edu/dataset/551/gas+turbine+co+and+nox+emission+data+set"},{"name":"ISIC 2016","url":"https://challenge.isic-archive.com/data/"},{"name":"DHI","url":"https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset"},{"name":"Default of Credit Card Clients","url":"https://archive.ics.uci.edu/dataset/350/default+of+credit+card+clients"},{"name":"Diabetes 130","url":"https://archive.ics.uci.edu/dataset/296/diabetes+130-us+hospitals+for+years+1999-2008"}],"type":"bootcamp","year":2025,"github_url":"https://github.com/VectorInstitute/interpretability"},{"name":"kg-rag","repo_id":"VectorInstitute/kg-rag","description":"A comprehensive framework for Knowledge Graph Retrieval Augmented Generation (KG-RAG).","implementations":[{"name":"KG-RAG","url":"https://vectorinstitute.github.io/kg-rag/"},{"name":"GraphRAG","url":"https://microsoft.github.io/graphrag/"}],"public_datasets":[{"name":"SEC 10-Q","url":"https://github.com/docugami/KG-RAG-datasets/blob/main/sec-10-q/README.md"}],"type":"applied-research","year":2025,"github_url":"https://github.com/VectorInstitute/kg-rag"},{"name":"linguamark","repo_id":"VectorInstitute/linguamark","description":"A benchmark for evaluating fairness and performance of Large Multimodal Models on multilingual Visual Question Answering tasks across 11 languages and 5 social attributes","implementations":[{"name":"LinguaMark Benchmark","url":"https://vectorinstitute.github.io/linguamark/"},{"name":"Bias Evaluation","url":null},{"name":"Answer Relevancy Evaluation","url":null},{"name":"Faithfulness Evaluation","url":null},{"name":"Model Inference Pipeline","url":null}],"public_datasets":[{"name":"LinguaMark Multilingual VQA Dataset","url":"https://github.com/VectorInstitute/linguamark"}],"type":"applied-research","year":2025,"github_url":"https://github.com/VectorInstitute/linguamark","paper_url":"https://arxiv.org/abs/2507.07274","bibtex":"raval2025linguamark"},{"name":"masksql","repo_id":"VectorInstitute/masksql","description":"A privacy-preserving framework for LLM-based text-to-SQL that uses schema masking and progressive unmasking to protect sensitive database information while maintaining query accuracy","implementations":[{"name":"MaskSQL","url":null}],"type":"applied-research","year":2025,"paper_url":"https://arxiv.org/abs/2509.23459","bibtex":"abedini2025masksql"},{"name":"mcp-goodnews","repo_id":"VectorInstitute/mcp-goodnews","description":"A Model Context Protocol (MCP) server that curates positive news stories using AI-powered sentiment analysis, integrating with Claude Desktop to deliver uplifting news","implementations":[{"name":"Uplifting News Aggregation","url":"https://github.com/VectorInstitute/mcp-goodnews/blob/main/src/mcp_goodnews/newsapi.py"},{"name":"Sentiment Analysis","url":"https://github.com/VectorInstitute/mcp-goodnews/blob/main/src/mcp_goodnews/goodnews_ranker.py"}],"type":"tool","year":2025,"github_url":"https://github.com/VectorInstitute/mcp-goodnews"},{"name":"midst-toolkit","repo_id":"VectorInstitute/midst-toolkit","description":"A toolkit for facilitating MIA resiliency testing on diffusion-model-based synthetic tabular data","implementations":[{"name":"Membership Inference Attacks (MIA)","url":"https://vectorinstitute.github.io/MIDST/"}],"type":"tool","year":2025,"github_url":"https://github.com/VectorInstitute/midst-toolkit"},{"name":"shared-encoder","repo_id":"VectorInstitute/shared-encoder","description":"A Shared Encoder Approach to Multimodal Representation Learning","implementations":[{"name":"Shared Encoder Architecture","url":"https://arxiv.org/abs/2503.01654"},{"name":"Multimodal Representation Learning","url":null}],"type":"applied-research","year":2025,"github_url":"https://github.com/VectorInstitute/shared-encoder","paper_url":"https://arxiv.org/abs/2503.01654","bibtex":"roy2025shared","public_datasets":[{"name":"PMC-OA","url":"https://pmc.ncbi.nlm.nih.gov/tools/openftlist/"},{"name":"MIMIC-CXR","url":"https://physionet.org/content/mimic-cxr/2.0.0/"},{"name":"DeepEyeNet","url":null},{"name":"Quilt","url":"https://quilt1m.github.io/"}]},{"name":"ai-deployment","repo_id":"VectorInstitute/ai-deployment","description":"A repository with reference implementations for deploying AI models in production environments, focusing on best practices and cloud-native solutions.","implementations":[{"name":"AWS","url":"https://github.com/VectorInstitute/ai-deployment/tree/main/implementations/aws"},{"name":"GCP","url":"https://github.com/VectorInstitute/ai-deployment/tree/main/implementations/gcp"}],"type":"bootcamp","year":2024,"github_url":"https://github.com/VectorInstitute/ai-deployment"},{"name":"atomgen","repo_id":"VectorInstitute/atomgen","description":"Library for handling atomistic graph datasets focusing on transformer-based implementations, with utilities for training various models, experimenting with different pre-training tasks, and a suite of pre-trained models with huggingface integrations","implementations":[{"name":"AtomFormer","url":null},{"name":"SchNet","url":"https://arxiv.org/abs/1706.08566"},{"name":"TokenGT","url":"https://github.com/jw9730/tokengt"}],"public_datasets":[{"name":"S2EF Datasets","url":"https://huggingface.co/datasets/vector-institute/s2ef-15m"},{"name":"Misc. Atomistic Graph Datasets","url":"https://huggingface.co/datasets/vector-institute/datasets"}],"type":"applied-research","year":2024,"github_url":"https://github.com/VectorInstitute/atomgen"},{"name":"bias-mitigation-unlearning","repo_id":"VectorInstitute/bias-mitigation-unlearning","description":"A repository for social bias mitigation in LLMs using machine unlearning","implementations":[{"name":"Negation via Task Vectors","url":"https://aclanthology.org/2024.emnlp-industry.71/"},{"name":"PCGU","url":"https://aclanthology.org/2024.emnlp-industry.71/"}],"type":"applied-research","year":2024,"github_url":"https://github.com/VectorInstitute/bias-mitigation-unlearning","paper_url":"https://aclanthology.org/2024.emnlp-industry.71/","bibtex":"dige2024can","public_datasets":[{"name":"BBQ","url":"https://github.com/nyu-mll/BBQ/tree/main/data"},{"name":"Stereoset","url":"https://github.com/moinnadeem/StereoSet/tree/master/data"},{"name":"RedditBias","url":"https://github.com/VectorInstitute/bias-mitigation-unlearning/tree/main/reddit_bias/data"}]},{"name":"cyclops","repo_id":"VectorInstitute/cyclops","description":"A toolkit for facilitating research and deployment of ML models for healthcare","implementations":[{"name":"Binary Classification","url":null},{"name":"Multi-label Classification","url":null},{"name":"Tabular Data Processing","url":null},{"name":"Time-series Data Processing","url":null},{"name":"Image Data Processing","url":null},{"name":"Dataset Shift Detection","url":null},{"name":"Model Report Card Generation","url":null}],"public_datasets":[{"name":"NIH Chest X-ray","url":"https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community"},{"name":"MIMIC-IV","url":"https://mimic.mit.edu/"}],"type":"tool","year":2024,"github_url":"https://github.com/VectorInstitute/cyclops","package_name":"pycyclops"},{"name":"diffusion-models","repo_id":"VectorInstitute/diffusion-models","description":"A repository with demos for various diffusion models for tabular and time series data","implementations":[{"name":"TabDDPM","url":"https://github.com/VectorInstitute/diffusion-models/tree/main/implementations/tabular/single_table_synthesis"},{"name":"TabSyn","url":"https://github.com/VectorInstitute/diffusion-models/tree/main/implementations/tabular/single_table_synthesis"},{"name":"ClavaDDPM","url":"https://github.com/VectorInstitute/diffusion-models/tree/main/implementations/tabular/multi_table_synthesis"},{"name":"CSDI","url":"https://github.com/VectorInstitute/diffusion-models/tree/main/implementations/time_series/csdi"},{"name":"TSDiff","url":"https://github.com/VectorInstitute/diffusion-models/tree/main/implementations/time_series/tsdiff"}],"public_datasets":[{"name":"Physionet Challenge 2012","url":"https://www.physionet.org/content/challenge-2012/1.0.0/"},{"name":"Electricity dataset (UCI Machine Learning Repository)","url":"https://archive.ics.uci.edu/dataset/321/electricityloaddiagrams20112014"}],"type":"bootcamp","year":2024,"github_url":"https://github.com/VectorInstitute/diffusion-models"},{"name":"finetuning-and-alignment","repo_id":"VectorInstitute/finetuning-and-alignment","description":"A repository with implementations advanced fine-tuning techniques and approaches to enhance Large Language Model performance, reduce their computational cost, with a focus on alignment with human values","implementations":[{"name":"FSDP","url":"https://docs.pytorch.org/tutorials/intermediate/FSDP_tutorial.html"},{"name":"DDP","url":"https://docs.pytorch.org/tutorials/intermediate/ddp_tutorial.html"},{"name":"Instruction Tuning","url":null},{"name":"PEFT","url":"https://github.com/huggingface/peft"},{"name":"Quantization","url":null},{"name":"Supervised Fine-tuning","url":null}],"public_datasets":[{"name":"SAMSum dataset","url":"https://huggingface.co/datasets/knkarthick/samsum"},{"name":"TweetEval","url":"https://github.com/cardiffnlp/tweeteval"}],"type":"bootcamp","year":2024,"github_url":"https://github.com/VectorInstitute/finetuning-and-alignment"},{"name":"fl4health","repo_id":"VectorInstitute/FL4Health","description":"A flexible, modular, and easy to use library to facilitate federated learning research and development in healthcare settings","implementations":[{"name":"FedAvg","url":"https://arxiv.org/abs/1602.05629"},{"name":"FedOpt","url":"https://arxiv.org/abs/2003.00295"},{"name":"FedProx","url":"https://arxiv.org/abs/1812.06127"},{"name":"SCAFFOLD","url":"https://arxiv.org/abs/1910.06378"},{"name":"MOON","url":"https://arxiv.org/abs/2103.16257"},{"name":"FedDG-GA","url":"https://arxiv.org/abs/2103.06030"},{"name":"FLASH","url":"https://proceedings.mlr.press/v202/panchal23a/panchal23a.pdf"},{"name":"FedPM","url":"https://arxiv.org/pdf/2209.15328"},{"name":"Personal FL","url":"https://arxiv.org/abs/2205.13692"},{"name":"FedBN","url":"https://arxiv.org/abs/2102.07623"},{"name":"FedPer","url":"https://arxiv.org/abs/1912.00818"},{"name":"FedRep","url":"https://arxiv.org/abs/2303.05206"},{"name":"Ditto","url":"https://arxiv.org/abs/2012.04221"},{"name":"MR-MTL","url":"https://arxiv.org/abs/2206.07902"},{"name":"APFL","url":"https://arxiv.org/abs/2003.13461"},{"name":"PerFCL","url":"https://ieeexplore.ieee.org/document/10020518/"},{"name":"FENDA-FL","url":"https://arxiv.org/pdf/2309.16825.pdf"},{"name":"FENDA+Ditto","url":null}],"type":"tool","year":2024,"github_url":"https://github.com/VectorInstitute/fl4health","package_name":"fl4health"},{"name":"florist","repo_id":"VectorInstitute/FLorist","description":"A platform to launch and monitor Federated Learning (FL) training jobs, designed to bridge the gap between FL algorithm implementations and practical healthcare applications","implementations":[{"name":"FL Job Orchestration","url":null},{"name":"Training Job Monitoring","url":null},{"name":"Client-Server Communication","url":null},{"name":"FL4Health Integration","url":null},{"name":"Web-based Job Configuration","url":null},{"name":"Docker-based Deployment","url":null},{"name":"Multi-client Support","url":null}],"type":"tool","year":2024,"github_url":"https://github.com/VectorInstitute/FLorist"},{"name":"mmlearn","repo_id":"VectorInstitute/mmlearn","description":"A toolkit for research on multimodal representation learning","implementations":[{"name":"Contrastive Pretraining","url":null},{"name":"I-JEPA","url":"https://arxiv.org/abs/2301.08243"}],"public_datasets":[{"name":"ImageNet","url":"https://www.image-net.org/"},{"name":"LibriSpeech","url":"https://www.openslr.org/12/"},{"name":"RGB-D","url":"https://rgbd.cs.princeton.edu/"}],"type":"tool","year":2024,"github_url":"https://github.com/VectorInstitute/mmlearn"},{"name":"odyssey","repo_id":"VectorInstitute/odyssey","description":"A comprehensive library for developing foundation models using Electronic Health Record (EHR) data, with a focus on advanced medical data processing and modeling","implementations":[{"name":"EHRMamba","url":"https://vectorinstitute.github.io/EHRMamba/"},{"name":"CEHR-BERT","url":null},{"name":"BigBird","url":"https://arxiv.org/abs/2007.14062"},{"name":"MultiBird","url":null},{"name":"LSTM","url":null},{"name":"XGBoost","url":null},{"name":"Multitask Prompted Finetuning (MPF)","url":null},{"name":"Next Token Prediction (NTP)","url":null}],"public_datasets":[{"name":"MIMIC-IV","url":"https://mimic.mit.edu/"}],"type":"tool","year":2024,"github_url":"https://github.com/VectorInstitute/odyssey"},{"name":"pmc-data-extraction","repo_id":"VectorInstitute/pmc-data-extraction","description":"A toolkit to download, augment, and benchmark Open-PMC data","implementations":[{"name":"PMC Data Extraction","url":"https://arxiv.org/abs/2503.14377"}],"public_datasets":[{"name":"PubMed Central","url":"https://pmc.ncbi.nlm.nih.gov/"},{"name":"HuggingFace PMC Dataset","url":"https://huggingface.co/datasets/vector-institute/open-pmc"}],"type":"applied-research","paper_url":"https://arxiv.org/abs/2503.14377","bibtex":"baghbanzadeh2025advancing","year":2024,"github_url":"https://github.com/VectorInstitute/pmc-data-extraction"},{"name":"retrieval-augmented-generation","repo_id":"vectorinstitute/retrieval-augmented-generation","description":"A repository reference implementations for retrieval-augmented generation","implementations":[{"name":"Web Search","url":"https://github.com/VectorInstitute/retrieval-augmented-generation/tree/main/implementations/web_search"},{"name":"Document Search","url":"https://github.com/VectorInstitute/retrieval-augmented-generation/tree/main/implementations/document_search"},{"name":"SQL Search","url":"https://github.com/VectorInstitute/retrieval-augmented-generation/tree/main/implementations/sql_search"},{"name":"Cloud Search","url":"https://github.com/VectorInstitute/retrieval-augmented-generation/tree/main/implementations/cloud_search"},{"name":"PubMed QA","url":"https://github.com/VectorInstitute/retrieval-augmented-generation/tree/main/implementations/pubmed_qa"},{"name":"RAG Evaluation","url":"https://github.com/VectorInstitute/retrieval-augmented-generation/tree/main/implementations/rag_evaluation"}],"public_datasets":[{"name":"PubMed","url":"https://pubmed.ncbi.nlm.nih.gov"},{"name":"Banking Dataset - Marketing Targets","url":"https://www.kaggle.com/datasets/prakharrathi25/banking-dataset-marketing-targets"}],"type":"bootcamp","year":2024,"github_url":"https://github.com/VectorInstitute/retrieval-augmented-generation","package_name":"aieng-rag-utils"},{"name":"self-supervised-learning","repo_id":"VectorInstitute/self-supervised-learning","description":"A repository with reference implementations of self-supervised learning techniques","implementations":[{"name":"Internal Contrastive Learning (ICL) + Latent Outlier Exposure (LOE)","url":"https://github.com/VectorInstitute/self-supervised-learning/tree/main/src/contrastive_learning"},{"name":"SimMTM","url":"https://github.com/VectorInstitute/self-supervised-learning/tree/main/src/masked_modelling/simmtm"},{"name":"TabRet","url":"https://github.com/VectorInstitute/self-supervised-learning/tree/main/src/masked_modelling/tabret"},{"name":"Data2Vec","url":"https://github.com/VectorInstitute/self-supervised-learning/tree/main/src/self_distillation"}],"public_datasets":[{"name":"STL-10","url":"https://cs.stanford.edu/~acoates/stl10/"},{"name":"Beijing PM 2.5","url":"https://archive.ics.uci.edu/dataset/381/beijing+pm2+5+data"}],"type":"bootcamp","year":2024,"github_url":"https://github.com/VectorInstitute/self-supervised-learning"},{"name":"vbll","repo_id":"VectorInstitute/vbll","description":"Simple and computationally efficient neural network uncertainty estimation via Variational Bayesian Last Layers - a deterministic variational approach for Bayesian last layers with quadratic complexity in last layer width","implementations":[{"name":"Variational Bayesian Last Layers (VBLL)","url":"https://arxiv.org/abs/2404.11599"},{"name":"VBLL for Regression","url":null},{"name":"VBLL for Classification","url":null}],"type":"applied-research","year":2024,"github_url":"https://github.com/VectorInstitute/vbll","paper_url":"https://arxiv.org/abs/2404.11599","bibtex":"harrison2024vbll","package_name":"vbll"},{"name":"vector-inference","repo_id":"VectorInstitute/vector-inference","description":"Efficient LLM inference on Slurm clusters using vLLM","type":"tool","year":2024,"github_url":"https://github.com/VectorInstitute/vector-inference","package_name":"vec-inf","implementations":["CLI","Python API","OpenAI compatible server"]},{"name":"anomaly-detection","repo_id":"VectorInstitute/anomaly-detection","description":"A repository with implementation of anomaly detection techniques","implementations":[{"name":"Logistic Regression (Supervised)"},{"name":"Random Forest (Supervised)"},{"name":"XGBoost (Supervised)"},{"name":"CatBoost (Supervised)"},{"name":"Light GBM (Supervised)"},{"name":"TabNet (Supervised and Semi-supervised)"},{"name":"Autoencoder (AE) (Unsupervised)"},{"name":"Isolation Forest (Unsupervised)"}],"public_datasets":[{"name":"Bank Account Fraud Detection","url":"https://arxiv.org/pdf/2211.13358.pdf"},{"name":"DGraph dataset","url":"https://dgraph.xinye.com/dataset"},{"name":"MVTec dataset","url":"https://www.mvtec.com/company/research/datasets/mvtec-ad"},{"name":"UCSD Anomaly Detection Dataset","url":"http://www.svcl.ucsd.edu/projects/anomaly/dataset.htm"},{"name":"UCF Crime Dataset","url":"https://www.kaggle.com/datasets/odins0n/ucf-crime-dataset"}],"type":"bootcamp","year":2023,"github_url":"https://github.com/VectorInstitute/anomaly-detection"},{"name":"hv-ai-c","repo_id":"VectorInstitute/HV-Ai-C","description":"A reinforcement learning solution for HVAC temperature control designed to minimize energy consumption in data centers and buildings. Available as the \'hnp\' package on PyPI.","implementations":[{"name":"Hyperspace Neighbour Penetration (HNP)","url":"https://arxiv.org/pdf/2106.05497.pdf"},{"name":"Q-Learning Agent with HNP","url":null},{"name":"Sinergym Integration","url":null},{"name":"Beobench Integration","url":null}],"type":"tool","year":2022,"github_url":"https://github.com/VectorInstitute/HV-Ai-C","package_name":"hnp"},{"name":"recommender-systems","repo_id":"VectorInstitute/recommender-systems","description":"A repository with implementations of recommender systems","implementations":[{"name":"Matrix Factorization","url":null},{"name":"Collaborative Filtering","url":null},{"name":"Content-Based Filtering","url":null},{"name":"Sequence Aware Recommender Systems","url":null},{"name":"Session-Based Recommender Systems","url":null},{"name":"Knowledge Graph-Based Recommender Systems","url":null}],"type":"bootcamp","year":2022,"github_url":"https://github.com/VectorInstitute/recommender-systems"},{"name":"privacy-enhancing-techniques","repo_id":"VectorInstitute/privacy-enhancing-techniques","description":"A repository with implementations of privacy-enhancing techniques for machine learning","implementations":[{"name":"Differential Privacy (tensorflow_privacy)","url":null},{"name":"PATE","url":null},{"name":"Membership Inference Attacks","url":null},{"name":"Horizontal Federated Learning","url":null},{"name":"Vertical Federated Learning","url":null},{"name":"Homomorphic Encryption","url":null}],"type":"bootcamp","year":2021,"github_url":"https://github.com/VectorInstitute/privacy-enhancing-techniques"}],"totalImplementations":145,"yearsOfResearch":7,"lastUpdated":"2025-12-03T19:27:21.654987"}');function N(){let[e,t]=(0,r.useState)("all"),a=(0,r.useMemo)(()=>{let e={all:j.repositories.length,"applied-research":0,bootcamp:0,tool:0};return j.repositories.forEach(t=>{e[t.type]=(e[t.type]||0)+1}),e},[j.repositories]),s=(0,r.useMemo)(()=>"all"===e?j.repositories:j.repositories.filter(t=>t.type===e),[e,j.repositories]);return(0,i.jsxs)("main",{className:"min-h-screen",children:[(0,i.jsx)(d,{totalImplementations:j.totalImplementations,yearsOfResearch:j.yearsOfResearch}),(0,i.jsx)("div",{className:"relative bg-gray-50 dark:bg-gray-900",children:(0,i.jsx)("div",{className:"max-w-7xl mx-auto px-4 py-20",children:(0,i.jsxs)("section",{id:"browse",className:"scroll-mt-20",children:[(0,i.jsxs)("div",{className:"text-center mb-12",children:[(0,i.jsxs)("h2",{className:"text-4xl md:text-5xl font-bold mb-4 text-gray-900 dark:text-white",children:["Browse ",(0,i.jsx)("span",{className:"bg-gradient-to-r from-vector-magenta to-vector-cobalt bg-clip-text text-transparent",children:"Implementations"})]}),(0,i.jsx)("p",{className:"text-gray-700 dark:text-gray-300 text-lg max-w-2xl mx-auto font-medium",children:"Discover AI implementations across various domains and techniques"})]}),(0,i.jsx)("div",{className:"max-w-3xl mx-auto mb-8",children:(0,i.jsx)("div",{className:"bg-white dark:bg-gray-800 rounded-lg border border-gray-200 dark:border-gray-700 p-5 shadow-sm",children:(0,i.jsxs)("div",{className:"flex items-start gap-3",children:[(0,i.jsx)("svg",{className:"w-5 h-5 text-vector-cobalt dark:text-vector-magenta flex-shrink-0 mt-0.5",fill:"none",stroke:"currentColor",viewBox:"0 0 24 24",children:(0,i.jsx)("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"})}),(0,i.jsxs)("div",{children:[(0,i.jsx)("h3",{className:"font-semibold text-gray-900 dark:text-white mb-2 text-sm",children:"What's an Implementation?"}),(0,i.jsx)("p",{className:"text-xs text-gray-700 dark:text-gray-300 leading-relaxed mb-2",children:"Executable code for ML algorithms, models, and techniques spanning individual methods to comprehensive libraries:"}),(0,i.jsxs)("ul",{className:"text-xs text-gray-700 dark:text-gray-300 space-y-1 ml-3",children:[(0,i.jsxs)("li",{className:"flex items-start gap-1.5",children:[(0,i.jsx)("span",{className:"text-vector-cobalt dark:text-vector-magenta",children:"•"}),(0,i.jsxs)("span",{children:[(0,i.jsx)("span",{className:"font-medium text-vector-cobalt dark:text-vector-magenta",children:"Applied Research"})," — novel experimentation and techniques often accompanying published work"]})]}),(0,i.jsxs)("li",{className:"flex items-start gap-1.5",children:[(0,i.jsx)("span",{className:"text-vector-cobalt dark:text-vector-magenta",children:"•"}),(0,i.jsxs)("span",{children:[(0,i.jsx)("span",{className:"font-medium text-vector-cobalt dark:text-vector-magenta",children:"Bootcamp"})," — demos and tutorials"]})]}),(0,i.jsxs)("li",{className:"flex items-start gap-1.5",children:[(0,i.jsx)("span",{className:"text-vector-cobalt dark:text-vector-magenta",children:"•"}),(0,i.jsxs)("span",{children:[(0,i.jsx)("span",{className:"font-medium text-vector-cobalt dark:text-vector-magenta",children:"Tool"})," — production-ready libraries for real-world use"]})]})]})]})]})})}),(0,i.jsx)(_,{}),(0,i.jsx)(b,{activeFilter:e,onFilterChange:t,counts:a}),(0,i.jsx)("div",{className:"grid grid-cols-1 lg:grid-cols-2 gap-6",children:s.map((e,t)=>(0,i.jsx)(I,{repository:e,index:t},e.repo_id))}),0===s.length&&(0,i.jsx)("div",{className:"text-center py-20",children:(0,i.jsx)("p",{className:"text-gray-600 dark:text-gray-400 text-lg",children:"No repositories found for this filter."})})]})})}),(0,i.jsx)("footer",{className:"bg-gray-100 dark:bg-gray-900 py-8 mt-20",children:(0,i.jsxs)("div",{className:"max-w-7xl mx-auto px-4 text-center",children:[(0,i.jsx)("div",{className:"mb-4 flex justify-center",children:(0,i.jsx)(n.default,{src:(0,u.O)("vector-logo.svg"),alt:"Vector Institute",width:120,height:48,className:"h-12 w-auto"})}),(0,i.jsxs)("p",{className:"text-gray-600 dark:text-gray-400 text-sm",children:["\xa9 ",new Date().getFullYear()," Vector Institute. All rights reserved."]}),(0,i.jsxs)("p",{className:"text-gray-500 dark:text-gray-500 text-xs mt-2",children:["Last updated: ",new Date(j.lastUpdated).toISOString().split("T")[0]]})]})})]})}}},e=>{e.O(0,[394,441,255,358],()=>e(e.s=230)),_N_E=e.O()}]);