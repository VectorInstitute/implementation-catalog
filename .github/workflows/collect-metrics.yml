name: Collect GitHub Metrics

on:
  # Run weekly on Mondays at 12:00 UTC (noon)
  # Later timing ensures PyPI stats are available for the previous day
  schedule:
    - cron: '0 12 * * 1'
  # Allow manual trigger
  workflow_dispatch:

permissions:
  contents: write

jobs:
  collect-metrics:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6
        with:
          # Use default fetch for faster checkout
          fetch-depth: 1
          # Ensure we're on the latest main branch
          ref: main

      - name: Setup GitHub CLI
        run: |
          # gh is pre-installed on GitHub Actions runners
          # Use METRICS_GITHUB_TOKEN if available (for traffic data), fallback to GITHUB_TOKEN
          TOKEN="${{ secrets.METRICS_GITHUB_TOKEN || secrets.GITHUB_TOKEN }}"
          echo "$TOKEN" | gh auth login --with-token

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          version: "0.9.11"
          enable-cache: true

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.12'

      - name: Install Python dependencies
        run: uv pip install --system pyyaml

      - name: Configure git
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

      - name: Ensure data directories exist
        run: |
          mkdir -p catalog/public/data
          mkdir -p catalog-analytics/public/data

      - name: Collect GitHub metrics
        id: collect
        run: |
          python scripts/collect_github_metrics.py
          if [ $? -ne 0 ]; then
            echo "error=true" >> $GITHUB_OUTPUT
            exit 1
          fi
          echo "error=false" >> $GITHUB_OUTPUT
        env:
          GH_TOKEN: ${{ secrets.METRICS_GITHUB_TOKEN || secrets.GITHUB_TOKEN }}

      - name: Collect fork metrics
        id: collect_forks
        run: |
          python scripts/collect_fork_metrics.py
          if [ $? -ne 0 ]; then
            echo "error=true" >> $GITHUB_OUTPUT
            echo "âš ï¸ Fork metrics collection failed, continuing anyway"
          else
            echo "error=false" >> $GITHUB_OUTPUT
          fi
        env:
          GH_TOKEN: ${{ secrets.METRICS_GITHUB_TOKEN || secrets.GITHUB_TOKEN }}

      - name: Validate JSON files
        run: |
          echo "Validating JSON files..."
          python -c "import json; json.load(open('catalog/public/data/github_metrics.json'))"
          python -c "import json; json.load(open('catalog/public/data/github_metrics_history.json'))"

          # Validate fork metrics if it exists
          if [ -f catalog-analytics/public/data/fork_metrics.json ]; then
            python -c "import json; json.load(open('catalog-analytics/public/data/fork_metrics.json'))"
            echo "âœ“ Fork metrics JSON is valid"
          fi

          echo "âœ“ JSON files are valid"

      - name: Check for changes
        id: check_changes
        run: |
          git add catalog/public/data/github_metrics.json
          git add catalog/public/data/github_metrics_history.json

          # Add fork metrics if it exists
          if [ -f catalog-analytics/public/data/fork_metrics.json ]; then
            git add catalog-analytics/public/data/fork_metrics.json
          fi

          if git diff --cached --quiet; then
            echo "changed=false" >> $GITHUB_OUTPUT
            echo "No changes to commit"
          else
            echo "changed=true" >> $GITHUB_OUTPUT
            echo "Changes detected, will commit"
          fi

      - name: Commit and push metrics data
        if: steps.check_changes.outputs.changed == 'true'
        run: |
          git commit -m "chore: update GitHub metrics data

          ðŸ¤– Automated weekly metrics collection

          - Updated current metrics snapshot
          - Added to historical metrics database
          - Updated fork analysis and geographic distribution

          Generated by: ${{ github.workflow }}
          Run ID: ${{ github.run_id }}"

          # Push with retry logic
          for i in {1..3}; do
            if git push origin main; then
              echo "âœ“ Successfully pushed changes"
              break
            else
              if [ $i -lt 3 ]; then
                echo "Push failed, retrying in 5 seconds... (attempt $i/3)"
                sleep 5
                git pull --rebase origin main
              else
                echo "Failed to push after 3 attempts"
                exit 1
              fi
            fi
          done

      - name: Create summary
        if: always()
        run: |
          echo "## GitHub Metrics Collection Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Workflow Run:** \`${{ github.workflow }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**Trigger:** \`${{ github.event_name }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**Date:** \`$(date -u)\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ steps.collect.outputs.error }}" == "true" ]; then
            echo "**Status:** âŒ Collection failed" >> $GITHUB_STEP_SUMMARY
            exit 0
          fi

          if [ -f catalog/public/data/github_metrics.json ]; then
            REPO_COUNT=$(python -c "import json; data=json.load(open('catalog/public/data/github_metrics.json')); print(len(data.get('repos', {})))")
            echo "**Repositories Tracked:** $REPO_COUNT" >> $GITHUB_STEP_SUMMARY

            LAST_UPDATED=$(python -c "import json; data=json.load(open('catalog/public/data/github_metrics.json')); print(data.get('last_updated', 'Unknown'))")
            echo "**Last Updated:** \`$LAST_UPDATED\`" >> $GITHUB_STEP_SUMMARY
          fi

          # Add fork metrics summary
          if [ -f catalog-analytics/public/data/fork_metrics.json ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Fork Analysis" >> $GITHUB_STEP_SUMMARY
            ACTIVE_FORKS=$(python -c "import json; data=json.load(open('catalog-analytics/public/data/fork_metrics.json')); print(data['summary']['active_forks'])")
            MEANINGFUL_FORKS=$(python -c "import json; data=json.load(open('catalog-analytics/public/data/fork_metrics.json')); print(data['summary']['meaningful_forks'])")
            COUNTRIES=$(python -c "import json; data=json.load(open('catalog-analytics/public/data/fork_metrics.json')); print(len(data['geographic_distribution']))")
            echo "**Active Forks:** $ACTIVE_FORKS" >> $GITHUB_STEP_SUMMARY
            echo "**Meaningful Forks:** $MEANINGFUL_FORKS" >> $GITHUB_STEP_SUMMARY
            echo "**Countries Represented:** $COUNTRIES" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ steps.check_changes.outputs.changed }}" == "true" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Status:** âœ… Metrics updated and committed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The deployment workflow will automatically trigger to publish the updated analytics." >> $GITHUB_STEP_SUMMARY
          else
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Status:** â„¹ï¸ No changes detected" >> $GITHUB_STEP_SUMMARY
          fi
