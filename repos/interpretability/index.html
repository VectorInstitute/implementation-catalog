<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>interpretability - Vector Implementation Catalog</title>
  <meta name="description" content="A repository providing reference implementations and resources for the 2025 Bootcamp on Interpretable and Explainable AI, covering both post-hoc explainability methods and interpretable models">
  <meta http-equiv="refresh" content="0; url=/implementation-catalog/#interpretability">
  <style>
    body {
      font-family: system-ui, -apple-system, sans-serif;
      max-width: 800px;
      margin: 50px auto;
      padding: 20px;
      line-height: 1.6;
    }
    .badge {
      display: inline-block;
      padding: 4px 12px;
      border-radius: 12px;
      font-size: 14px;
      margin: 5px 5px 5px 0;
    }
    .type-badge { background: #e0f2fe; color: #0369a1; }
    .year-badge { background: #f0fdf4; color: #15803d; }
    h1 { color: #111827; margin-bottom: 10px; }
    h3 { color: #374151; margin-top: 20px; }
    ul { list-style: none; padding: 0; }
    li {
      background: #f9fafb;
      padding: 8px 12px;
      margin: 5px 0;
      border-radius: 6px;
    }
    .description { color: #4b5563; margin: 20px 0; }
    .link { color: #0891b2; text-decoration: none; }
    .redirect-notice {
      background: #fef3c7;
      border: 1px solid #fbbf24;
      padding: 15px;
      border-radius: 8px;
      margin-bottom: 20px;
    }
  </style>
</head>
<body data-pagefind-body>
  <div class="redirect-notice">
    <strong>Redirecting...</strong> If you're not redirected, <a href="/implementation-catalog/#interpretability" class="link">click here</a>.
  </div>

  <article>
    <div>
      <span class="badge type-badge" data-pagefind-filter="type">bootcamp</span>
      <span class="badge year-badge" data-pagefind-filter="year">2025</span>
    </div>

    <h1 data-pagefind-meta="title">interpretability</h1>

    <p class="description" data-pagefind-meta="description">A repository providing reference implementations and resources for the 2025 Bootcamp on Interpretable and Explainable AI, covering both post-hoc explainability methods and interpretable models</p>

    <p>
      <a href="https://github.com/VectorInstitute/interpretability" target="_blank" rel="noopener noreferrer" class="link">View on GitHub</a>
    </p>

    
      <div class="implementations">
        <h3>Implementations</h3>
        <ul>
          <li>LIME</li>
          <li>SHAP</li>
          <li>PDP (Partial Dependence Plot)</li>
          <li>ALE (Accumulated Local Effects)</li>
          <li>Integrated Gradients</li>
          <li>Counterfactual Explanations</li>
          <li>Generalized Additive Model</li>
          <li>Neural Additive Model</li>
          <li>Explainable Boosting Machine</li>
        </ul>
      </div>
    
    
      <div class="datasets">
        <h3>Datasets</h3>
        <ul>
          <li>Gas turbine dataset</li>
          <li>ISIC 2016</li>
          <li>DHI</li>
          <li>Default of Credit Card Clients</li>
          <li>Diabetes 130</li>
        </ul>
      </div>
    
  </article>

  <script>
    // Redirect to main page with hash
    window.location.href = '/implementation-catalog/#interpretability';
  </script>
</body>
</html>